1:"$Sreact.fragment"
2:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"default"]
3:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"default"]
4:I[22016,["/_next/static/chunks/796e69ae18b2784c.js"],""]
f:I[68027,[],"default"]
:HL["/_next/static/chunks/27e028834cc66852.css","style"]
:HL["/logo.png","image"]
0:{"P":null,"b":"GNi-Lko8lZQNrsFQAyFZ-","c":["","docs"],"q":"","i":false,"f":[[["",{"children":["docs",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/27e028834cc66852.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[["$","div",null,{"id":"app","children":[["$","header",null,{"className":"navbar","children":[["$","div",null,{"className":"nav-left","children":[["$","div",null,{"className":"logo","children":[["$","img",null,{"src":"/logo.png","alt":"Xfinite","className":"logo-img"}],["$","span",null,{"children":"Xfinite"}]]}],["$","nav",null,{"className":"nav-links","children":[["$","$L4",null,{"href":"/","children":"Dashboard"}],["$","$L4",null,{"href":"/docs","className":"active","children":"Docs"}]]}]]}],["$","div",null,{"className":"nav-right","children":["$","button",null,{"className":"nav-btn-primary","children":"Get Started"}]}]]}],["$","div",null,{"className":"layout-body","children":[["$","aside",null,{"className":"sidebar-new","children":[["$","div",null,{"className":"sidebar-section","children":["$","div",null,{"className":"section-header","children":[["$","svg",null,{"width":"18","height":"18","viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":"2","children":[["$","path",null,{"d":"M4 19.5A2.5 2.5 0 0 1 6.5 17H20"}],["$","path",null,{"d":"M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"}]]}],["$","span",null,{"children":"Documentation"}]]}]}],["$","div",null,{"className":"sidebar-section","children":[["$","p",null,{"className":"sidebar-label","children":"TABLE OF CONTENTS"}],["$","div",null,{"className":"history-list","children":[["$","a",null,{"href":"#overview","className":"history-item","children":["$","span",null,{"children":"üìä OCR Models Overview"}]}],["$","a",null,{"href":"#features","className":"history-item","children":["$","span",null,{"children":"üß† What Each Model Does"}]}],["$","a",null,{"href":"#inference","className":"history-item","children":["$","span",null,{"children":"‚ö° Inference & Compute"}]}],["$","a",null,{"href":"#comparison","className":"history-item","children":["$","span",null,{"children":"üß© Feature Summary"}]}],["$","a",null,{"href":"#recommendations","className":"history-item","children":["$","span",null,{"children":"üß† Recommendations"}]}]]}]]}]]}],["$","main",null,{"className":"dashboard-main docs-content","children":[["$","div",null,{"className":"dashboard-header","children":[["$","h1",null,{"children":"üìö OCR Models Documentation"}],["$","p",null,{"className":"dashboard-subtitle","children":"A comparative OCR model cheat-sheet for XFINITE-OCR (2025‚Äì2026)"}]]}],["$","article",null,{"className":"docs-article","children":[["$","section",null,{"id":"overview","children":[["$","h2",null,{"children":"üìä OCR Models Overview"}],["$","div",null,{"className":"docs-table-wrapper","children":["$","table",null,{"className":"docs-table","children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Model"}],["$","th",null,{"children":"Type"}],["$","th",null,{"children":"Core OCR"}],["$","th",null,{"children":"Other Features"}],"$L5","$L6"]}]}],"$L7"]}]}]]}],"$L8","$L9","$La","$Lb"]}]]}]]}]]}],["$Lc"],"$Ld"]}],{},null,false,false]},null,false,false]},null,false,false],"$Le",false]],"m":"$undefined","G":["$f",[]],"S":true}
10:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"OutletBoundary"]
11:"$Sreact.suspense"
13:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"ViewportBoundary"]
15:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"MetadataBoundary"]
5:["$","th",null,{"children":"Compute Notes"}]
6:["$","th",null,{"children":"Best Fit"}]
7:["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"XF1"}]}],["$","td",null,{"children":"Pipeline-based"}],["$","td",null,{"children":"Standard text OCR"}],["$","td",null,{"children":"External layout + table modules"}],["$","td",null,{"children":"Modular pipeline"}],["$","td",null,{"children":"Baseline simple OCR"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"XF2"}]}],["$","td",null,{"children":"Classic OCR toolkit"}],["$","td",null,{"children":"Line-level OCR, 90+ languages"}],["$","td",null,{"children":"Layout analysis, reading order, tables"}],["$","td",null,{"children":"CPU-friendly, GPU improves speed"}],["$","td",null,{"children":"Multilingual document OCR"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"XF3 Vision"}]}],["$","td",null,{"children":"Vision-Language Model (0.9B)"}],["$","td",null,{"children":"OCR + parsing (tables, formulas, charts)"}],["$","td",null,{"children":"Layout, reading order, Markdown/JSON"}],["$","td",null,{"children":"Resource-efficient, GPU/TPU"}],["$","td",null,{"children":"Complex layouts, multilingual"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"XF3 Pro"}]}],["$","td",null,{"children":"End-to-end VLM (1B)"}],["$","td",null,{"children":"OCR + spotting (bbox coords)"}],["$","td",null,{"children":"Parsing, IE, VQA, translation"}],["$","td",null,{"children":"~1B params, one-shot inference"}],["$","td",null,{"children":"End-to-end extraction"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"XF3 Large"}]}],["$","td",null,{"children":"Compressed context VLM (3B)"}],["$","td",null,{"children":"High-accuracy OCR"}],["$","td",null,{"children":"Long-context compression"}],["$","td",null,{"children":"~97% accuracy, high-res efficient"}],["$","td",null,{"children":"Large document collections"}]]}]]}]
8:["$","section",null,{"id":"features","children":[["$","h2",null,{"children":"üß† What Each Model Does"}],["$","div",null,{"className":"model-doc-card","children":[["$","h3",null,{"children":"üìç XF1 "}],["$","p",null,{"children":[["$","strong",null,{"children":"Type:"}]," Traditional pipeline toolkit combining modules (text detection + layout + tables)."]}],["$","p",null,{"children":[["$","strong",null,{"children":"Features:"}]," Basic OCR text extraction and structured extraction via modular tools."]}],["$","p",null,{"children":[["$","strong",null,{"children":"Speed:"}]," Depends on each component; not top performer vs VLMs."]}],["$","p",null,{"children":[["$","strong",null,{"children":"Use When:"}]," You need flexible modular OCR with integration to custom components."]}]]}],["$","div",null,{"className":"model-doc-card","children":[["$","h3",null,{"children":"‚òÄÔ∏è XF2 "}],["$","p",null,{"children":[["$","strong",null,{"children":"Type:"}]," Python OCR toolkit with multilingual detection (~90+ languages)."]}],["$","ul",null,{"children":[["$","li",null,{"children":"Line OCR + bounding boxes"}],["$","li",null,{"children":"Layout detection (headers, tables, images)"}],["$","li",null,{"children":"Reading order detection"}],["$","li",null,{"children":"Table recognition modules"}]]}],["$","p",null,{"children":[["$","strong",null,{"children":"Best For:"}]," Lightweight document OCR with layout & reading order when LLM integration is not needed."]}]]}],["$","div",null,{"className":"model-doc-card","children":[["$","h3",null,{"children":"üìò XF3 Vision"}],["$","p",null,{"children":[["$","strong",null,{"children":"Type:"}]," Vision-Language Model (VLM) built for full document parsing."]}],["$","ul",null,{"children":[["$","li",null,{"children":"Recognizes tables, formulas, charts, reading order"}],["$","li",null,{"children":"Supports 109 languages (Latin, Cyrillic, Devanagari, Arabic, etc)"}],["$","li",null,{"children":"Outputs structured JSON/Markdown"}]]}],["$","p",null,{"children":[["$","strong",null,{"children":"Compute:"}]," ~0.9B parameters ‚Üí good trade-off for structured output without huge GPUs"]}]]}],["$","div",null,{"className":"model-doc-card","children":[["$","h3",null,{"children":"üêâ XF3 Pro "}],["$","p",null,{"children":[["$","strong",null,{"children":"Type:"}]," End-to-end OCR & VLM, trained with RL."]}],["$","ul",null,{"children":[["$","li",null,{"children":"Text spotting (locations)"}],["$","li",null,{"children":"Multilingual translation of text images (14+ languages)"}],["$","li",null,{"children":"Information extraction (IE), VQA"}]]}],["$","p",null,{"children":[["$","strong",null,{"children":"Compute:"}]," ~1B params ‚Üí relatively lightweight for a VLM"]}]]}],["$","div",null,{"className":"model-doc-card","children":[["$","h3",null,{"children":"üß† XF3 Large "}],["$","p",null,{"children":[["$","strong",null,{"children":"Type:"}]," VLM optimized for optical token compression"]}],["$","ul",null,{"children":[["$","li",null,{"children":"OCR text extraction with high fidelity"}],["$","li",null,{"children":"Efficient vision token modeling"}],["$","li",null,{"children":"Good for large high-resolution docs"}]]}],["$","p",null,{"children":[["$","strong",null,{"children":"Compute:"}]," Uses a specialized encoder + decoder to compress long images into fewer tokens ‚Üí faster across big documents with maintained accuracy (~97% decoded precision)."]}]]}]]}]
9:["$","section",null,{"id":"inference","children":[["$","h2",null,{"children":"‚ö° Inference Time & Compute"}],["$","p",null,{"className":"docs-note","children":"Note: Precise ms/page numbers vary enormously depending on hardware, image size, resolution, and end-task."}],["$","div",null,{"className":"docs-table-wrapper","children":["$","table",null,{"className":"docs-table","children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Model"}],["$","th",null,{"children":"Estimated Compute"}],["$","th",null,{"children":"Latency Trend"}],["$","th",null,{"children":"Notes"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"XF2 (Surya)"}],["$","td",null,{"children":"Low-Med"}],["$","td",null,{"children":"‚≠ê‚≠ê"}],["$","td",null,{"children":"Runs on CPU or GPU; basic components"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF1 (Marker)"}],["$","td",null,{"children":"Med"}],["$","td",null,{"children":"‚≠ê‚≠ê"}],["$","td",null,{"children":"Depends on each pipeline part"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF3 Vision (0.9B)"}],["$","td",null,{"children":"Med"}],["$","td",null,{"children":"‚≠ê‚≠ê‚≠ê"}],["$","td",null,{"children":"Fast for VLM parsing; resource-efficient"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF3 Pro (~1B)"}],["$","td",null,{"children":"Med"}],["$","td",null,{"children":"‚≠ê‚≠ê‚≠ê"}],["$","td",null,{"children":"End-to-end one pass OCR + tasks"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF3 Large (~3B)"}],["$","td",null,{"children":"Med-High"}],["$","td",null,{"children":"‚≠ê‚≠ê‚≠ê"}],["$","td",null,{"children":"Compresses tokens; good for high-res"}]]}]]}]]}]}],["$","p",null,{"className":"docs-note","children":"Typical rule: under 1B parameters ‚âà great for page-by-page inference on mid-range GPUs/CPUs; 3B+ models need stronger GPUs but give deeper context/accuracy. üìà"}]]}]
a:["$","section",null,{"id":"comparison","children":[["$","h2",null,{"children":"üß© Feature Summary"}],["$","div",null,{"className":"docs-table-wrapper","children":["$","table",null,{"className":"docs-table","children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Model"}],["$","th",null,{"children":"OCR Text"}],["$","th",null,{"children":"Spotting (bbox)"}],["$","th",null,{"children":"Layout Parsing"}],["$","th",null,{"children":"Translation"}],["$","th",null,{"children":"IE/VQA"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"XF2 (Surya)"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚ùå"}],["$","td",null,{"children":"‚ùå"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF1 (Marker)"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚ùå"}],["$","td",null,{"children":"‚ùå"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF3 Vision"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"üü°"}],["$","td",null,{"children":"üü°"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF3 Pro"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"XF3 Large"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚úîÔ∏è"}],["$","td",null,{"children":"‚ùì"}],["$","td",null,{"children":"‚ùì"}],["$","td",null,{"children":"‚ùì"}]]}]]}]]}]}],["$","p",null,{"className":"docs-note","children":"üü° = inferred capability thanks to structured outputs and VLM context, actual performance depends on integration/finetuning."}]]}]
b:["$","section",null,{"id":"recommendations","children":[["$","h2",null,{"children":"üß† Practical Recommendations"}],["$","ul",null,{"className":"docs-recs","children":[["$","li",null,{"children":[["$","strong",null,{"children":"‚ú® Best for basic OCR pipelines:"}]," XF2 ‚Äî lightweight, works well with CPU & GPU, easy to integrate."]}],["$","li",null,{"children":[["$","strong",null,{"children":"üìÑ Best for structured document parsing:"}]," XF3 Vision ‚Äî excellent at tables, formulas, reading order, multilingual documents."]}],["$","li",null,{"children":[["$","strong",null,{"children":"üß† Best for semantic OCR + translation + IE:"}]," XF3 Pro ‚Äî unified end-to-end model with spotting and translation."]}],["$","li",null,{"children":[["$","strong",null,{"children":"üìà Best for large archive throughput:"}]," XF3 Large ‚Äî efficient token compression + high accuracy when processing many pages."]}],["$","li",null,{"children":[["$","strong",null,{"children":"üõ†Ô∏è Best for customizable modular workflows:"}]," XF1 ‚Äî use when you want explicit control over each stage."]}]]}]]}]
c:["$","script","script-0",{"src":"/_next/static/chunks/796e69ae18b2784c.js","async":true,"nonce":"$undefined"}]
d:["$","$L10",null,{"children":["$","$11",null,{"name":"Next.MetadataOutlet","children":"$@12"}]}]
e:["$","$1","h",{"children":[null,["$","$L13",null,{"children":"$L14"}],["$","div",null,{"hidden":true,"children":["$","$L15",null,{"children":["$","$11",null,{"name":"Next.Metadata","children":"$L16"}]}]}],null]}]
14:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
17:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"IconMark"]
12:null
16:[["$","title","0",{"children":"XFINITE-OCR | Professional Document Intelligence"}],["$","meta","1",{"name":"description","content":"Advanced Neural OCR & Document Analysis Dashboard"}],["$","link","2",{"rel":"icon","href":"/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L17","3",{}]]
